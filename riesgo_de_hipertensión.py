# -*- coding: utf-8 -*-
"""Riesgo_de_hipertensión.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cYta44IV2nNmIOGmSxBxeFP13CHtTrF3
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.covariance import MinCovDet
from scipy.spatial.distance import mahalanobis
from scipy.stats import chi2
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score
import statsmodels.api as sm
import statsmodels.stats.api as sms
from sklearn.linear_model import LinearRegression
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.stats.diagnostic import acorr_breusch_godfrey

# DATAFRAME SIN MODIFICACIONES

df_antropometria_original=pd.read_csv("https://raw.githubusercontent.com/dxnxlsxn/Proyectos/refs/heads/main/ensaantro2022_entrega_w.csv",sep=";")
#Se identifican las variables de interés
columnas_a_conservar = [
    'FOLIO_INT', 'an27_01s','an27_02s','an27_03s','an27_01d','an27_02d','an27_03d','an30','an01_1','an01_2','an03','an11','an12_1','an12_2','an14',
    'an04_1','an04_2','an05','an15_1','an15_2','an16','an06'
]

# Seleccionar solo las columnas deseadas
df_antropometria = df_antropometria_original[columnas_a_conservar].copy()
#Se les asigna un nombre nuevo
df_antropometria.rename(columns={'an27_01s':'tension_sistolica1', 'an27_02s':'tension_sistolica2','an27_03s':'tension_sistolica3',
                                 'an27_01d':'tension_diastolica1','an27_02d':'tension_diastolica2','an27_03d':'tension_diastolica3',
                                 'an01_1':'peso1','an01_2':'peso2','an04_1':'altura1','an04_2':'altura2',
                                 'an08_1':'cintura1','an08_2':'cintura2'}, inplace=True)

#Debido a que la mayoría de las variables en primera instancia son reconocidas como texto, se remueven los guiones bajos y las comas son reemplazadas por un punto
df_antropometria['FOLIO_INT']=df_antropometria['FOLIO_INT'].replace({'_': ''}, regex=True)
df_antropometria= df_antropometria.replace({',': '.'}, regex=True)
#Se transforman los datos al tipo número
df_antropometria = df_antropometria.apply(pd.to_numeric, errors='coerce')

#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

df_examen_original=pd.read_csv("https://raw.githubusercontent.com/dxnxlsxn/Proyectos/refs/heads/main/Determinaciones_bioqu%C3%ADmicas_cronicas_deficiencias_9feb23.csv",sep=";")
#Se identifican las variables de interés
columnas_a_conservar = [
    'FOLIO_INT', 'entidad','h0302','h0303','san01','san04','hb01','valor_HB1AC','valor_AC_URICO', 'valor_ALBU', 'valor_COL_HDL', 'valor_COL_LDL',
    'valor_COLEST', 'valor_CREAT', 'valor_GLU_SUERO', 'valor_INSULINA', 'valor_TRIG'
]

# Seleccionar solo las columnas deseadas
df_examen = df_examen_original[columnas_a_conservar].copy()
#Se les asigna un nombre nuevo
df_examen.rename(columns={'h0302':'sexo','h0303':'edad','san04':'horas_en_ayuno','valor_HB1AC':'hemoglobina_glucosilada'}, inplace=True)

#Debido a que la mayoría de las variables en primera instancia son reconocidas como texto, se remueven los guiones bajos y las comas son reemplazadas por un punto
df_examen['FOLIO_INT']=df_examen['FOLIO_INT'].replace({'_': ''}, regex=True)
df_examen= df_examen.replace({',': '.'}, regex=True)
#Se transforman los datos al tipo número
df_examen = df_examen.apply(pd.to_numeric, errors='coerce')

#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

df_diagnostico_original = pd.read_csv("https://raw.githubusercontent.com/dxnxlsxn/Proyectos/refs/heads/main/ensadul2022.csv", sep=";")

# Se identifican las variables de interés
columnas_a_conservar = [
    'FOLIO_INT', 'a0401','a0301'
]

# Seleccionar solo las columnas deseadas
df_diagnostico = df_diagnostico_original[columnas_a_conservar].copy()

# Se les asigna un nombre nuevo
df_diagnostico.rename(columns={'a0401': 'hipertension_diagnosticada','a0301': 'diabetes_diagnosticada'}, inplace=True)

# Debido a que la mayoría de las variables en primera instancia son reconocidas como texto,
# se remueven los guiones bajos y las comas son reemplazadas por un punto
df_diagnostico['FOLIO_INT'] = df_diagnostico['FOLIO_INT'].replace({'_': ''}, regex=True)
# df_diagnostico = df_diagnostico.replace({',': '.'}, regex=True)

# Se transforman los datos al tipo número
df_diagnostico = df_diagnostico.apply(pd.to_numeric, errors='coerce')

#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

df_aux = pd.merge(
    left=df_examen,           # Primer DataFrame
    right=df_antropometria,          # Segundo DataFrame
    on='FOLIO_INT',     # Columna común para la unión
    how='inner'         # Tipo de unión: inner join
)
df_2022 = pd.merge(
    left=df_aux,           # Primer DataFrame
    right=df_diagnostico,          # Segundo DataFrame
    on='FOLIO_INT',     # Columna común para la unión
    how='inner'         # Tipo de unión: inner join
)


# Columnas a verificar
columnas_tension = [
    'tension_sistolica1',
    'tension_sistolica2',
    'tension_sistolica3',
    'tension_diastolica1',
    'tension_diastolica2',
    'tension_diastolica3'
]

df_2022[columnas_tension] = df_2022[columnas_tension].replace(999, float('nan'))

# Eliminar SOLO filas donde TODAS las columnas de tensión son nulas
df_2022 = df_2022.dropna(subset=columnas_tension, how='all')

df_2022.info()

#1-Hombre, 2-Mujer
df_examen_original_2020=pd.read_csv("https://raw.githubusercontent.com/dxnxlsxn/Proyectos/refs/heads/main/toma_de_sangre_ensanut2020_diab_w.csv")
#Se identifican las variables de interés
columnas_a_conservar = [
    'FOLIO_INT', 'ENTIDAD','H0302','H0303','san01','san04','HB1AC.Valor','valor.AC_URICO', 'valor.ALBUM', 'valor.COL_HDL', 'valor.COL_LDL',
    'valor.COLEST', 'valor.CREAT', 'valor.GLU_SUERO', 'valor.INSULINA', 'valor.TRIG'
]


# Seleccionar solo las columnas deseadas
df_examen_2020 = df_examen_original_2020[columnas_a_conservar].copy()
#Se les asigna un nombre nuevo
df_examen_2020.rename(columns={'ENTIDAD':'entidad','H0302':'sexo','H0303':'edad','san04':'horas_en_ayuno','HB1AC.Valor':'hemoglobina_glucosilada','valor.AC_URICO':'valor_AC_URICO',
                               'valor.ALBUM':'valor_ALBU','valor.COL_HDL':'valor_COL_HDL','valor.COL_LDL':'valor_COL_LDL','valor.COLEST':'valor_COLEST',
                               'valor.CREAT':'valor_CREAT','valor.GLU_SUERO':'valor_GLU_SUERO','valor.INSULINA':'valor_INSULINA', 'valor.TRIG':'valor_TRIG'}, inplace=True)

#Debido a que la mayoría de las variables en primera instancia son reconocidas como texto, se remueven los guiones bajos y las comas son reemplazadas por un punto
df_examen_2020['FOLIO_INT']=df_examen_2020['FOLIO_INT'].replace({'_': ''}, regex=True)
#df_examen_2020= df_examen_2020.replace({',': '.'}, regex=True)
#Se transforman los datos al tipo número
df_examen_2020 = df_examen_2020.apply(pd.to_numeric, errors='coerce')

#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

df_antropometria_original_2020 = pd.read_csv("https://raw.githubusercontent.com/dxnxlsxn/Proyectos/refs/heads/main/antropometria_ensanut2020_w.csv")

# Se identifican las variables de interés
columnas_a_conservar = [
    'FOLIO_INT', 'an08_01s','an08_02s','an08_03s','an08_01d','an08_02d','an08_03d','an11','an01_1','an01_2','an03',
    'an04_01','an04_02','an05','an06'
]

# Seleccionar solo las columnas deseadas
df_antropometria_2020 = df_antropometria_original_2020[columnas_a_conservar].copy()

# Se les asigna un nombre nuevo
df_antropometria_2020.rename(columns={'an08_01s':'tension_sistolica1', 'an08_02s':'tension_sistolica2','an08_03s':'tension_sistolica3',
                                      'an08_01d':'tension_diastolica1','an08_02d':'tension_diastolica2','an08_03d':'tension_diastolica3',
                                      'an01_1':'peso1','an01_2':'peso2','an04_01':'altura1','an04_02':'altura2',
                                      'an08_1':'cintura1','an08_2':'cintura2'}, inplace=True)

# Se remueven los guiones bajos y las comas se reemplazan por un punto
df_antropometria_2020['FOLIO_INT'] = df_antropometria_2020['FOLIO_INT'].replace({'_': ''}, regex=True)

# Se transforman los datos al tipo numérico
df_antropometria_2020 = df_antropometria_2020.apply(pd.to_numeric, errors='coerce')

#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

df_diagnostico2020_original = pd.read_csv("https://raw.githubusercontent.com/dxnxlsxn/Proyectos/refs/heads/main/integrantes_ensanut2020_w.csv", sep=";")

# Se identifican las variables de interés
columnas_a_conservar = [
    'FOLIO_INT', 'H0902A','H0902B','H0902C','H0902D','H0902E','H0902F','H0902G','H0902H'
]

# Seleccionar solo las columnas deseadas
df_diagnostico2020 = df_diagnostico2020_original[columnas_a_conservar].copy()

# Debido a que la mayoría de las variables en primera instancia son reconocidas como texto,
# se remueven los guiones bajos y las comas son reemplazadas por un punto

df_diagnostico2020['FOLIO_INT'] = df_diagnostico2020['FOLIO_INT'].replace({'_': ''}, regex=True)
df_diagnostico2020['FOLIO_INT'] = df_diagnostico2020['FOLIO_INT'].astype(str).str.slice(start=4)

# Se transforman los datos al tipo número
df_diagnostico2020 = df_diagnostico2020.apply(pd.to_numeric, errors='coerce')

#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

df_aux = pd.merge(
    left=df_examen_2020,           # Primer DataFrame
    right=df_antropometria_2020,          # Segundo DataFrame
    on='FOLIO_INT',     # Columna común para la unión
    how='inner'         # Tipo de unión: inner join
)
df_2020 = pd.merge(
    left=df_aux,           # Primer DataFrame
    right=df_diagnostico2020,          # Segundo DataFrame
    on='FOLIO_INT',     # Columna común para la unión
    how='inner'         # Tipo de unión: inner join
)

# Columnas a verificar
columnas_tension = [
    'tension_sistolica1',
    'tension_sistolica2',
    'tension_sistolica3',
    'tension_diastolica1',
    'tension_diastolica2',
    'tension_diastolica3'
]

df_2020[columnas_tension] = df_2020[columnas_tension].replace(999, float('nan'))

# Eliminar SOLO filas donde TODAS las columnas de tensión son nulas
df_2020 = df_2020.dropna(subset=columnas_tension, how='all')

df_2020.info()

columnas=['FOLIO_INT','entidad','sexo']
df_sin_filtro = pd.concat([df_2022, df_2020], ignore_index=True)
df_sin_filtro.info()

"""FILTROS"""

df_antropometria_original=pd.read_csv("https://raw.githubusercontent.com/dxnxlsxn/Proyectos/refs/heads/main/ensaantro2022_entrega_w.csv",sep=";")
#Se identifican las variables de interés
columnas_a_conservar = [
    'FOLIO_INT', 'an27_01s','an27_02s','an27_03s','an27_01d','an27_02d','an27_03d','an30','an01_1','an01_2','an03','an11','an12_1','an12_2','an14',
    'an04_1','an04_2','an05','an15_1','an15_2','an16','an06'
]

# Seleccionar solo las columnas deseadas
df_antropometria = df_antropometria_original[columnas_a_conservar].copy()
#Se les asigna un nombre nuevo
df_antropometria.rename(columns={'an27_01s':'tension_sistolica1', 'an27_02s':'tension_sistolica2','an27_03s':'tension_sistolica3',
                                 'an27_01d':'tension_diastolica1','an27_02d':'tension_diastolica2','an27_03d':'tension_diastolica3',
                                 'an01_1':'peso1','an01_2':'peso2','an04_1':'altura1','an04_2':'altura2',
                                 'an08_1':'cintura1','an08_2':'cintura2'}, inplace=True)

#Debido a que la mayoría de las variables en primera instancia son reconocidas como texto, se remueven los guiones bajos y las comas son reemplazadas por un punto
df_antropometria['FOLIO_INT']=df_antropometria['FOLIO_INT'].replace({'_': ''}, regex=True)
df_antropometria= df_antropometria.replace({',': '.'}, regex=True)
#Se transforman los datos al tipo número
df_antropometria = df_antropometria.apply(pd.to_numeric, errors='coerce')

#Tensión arterial
#Se conservan aquellas mediciones que reportan no tener problema (an30=1)
df_antropometria = df_antropometria.loc[(df_antropometria['an30']==1)]
df_antropometria.drop(['an30'], axis=1, inplace=True)

#Peso corporal para personas de 20 a 59 años
#Se conservan aquellas mediciones que reportan no tener problema (an03=1) y se reemplazan con NaN aquellas observaciones con el código 222.22, pues representan mediciones no realizadas
df_antropometria[['peso1', 'peso2']] = df_antropometria[['peso1', 'peso2']].replace(222.22, np.nan)
df_antropometria = df_antropometria.loc[(df_antropometria['an03']!=2) & (df_antropometria['an03']!=3)]
df_antropometria.drop(['an03'], axis=1, inplace=True)

#Peso corporal para personas con 60 años o más
#Se conservan aquellas mediciones que reportan no tener problema (an14=1) y se reemplazan con NaN aquellas observaciones con el código 222.22, pues representan mediciones no realizadas
df_antropometria[['an12_1','an12_2']] = df_antropometria[['an12_1','an12_2']].replace(222.22, np.nan)
#Si la columna de peso1 o peso2 están vacías (personas de 20 a 59 años), se les asigna el valor disponible para personas de 60 años o más respectivamente
df_antropometria['peso1'] = df_antropometria['peso1'].fillna(df_antropometria['an12_1'])
df_antropometria['peso2'] = df_antropometria['peso2'].fillna(df_antropometria['an12_2'])
df_antropometria = df_antropometria.loc[(df_antropometria['an14']!=2) & (df_antropometria['an14']!=3)]
df_antropometria.drop(['an14'], axis=1, inplace=True)
#Al haber concentrado la primera y segunda medición del peso en peso1 y peso2, eliminamos las columnas referentes a la primera y segunda medición del peso para personas de 60 o más años
df_antropometria.drop(['an12_1','an12_2'], axis=1, inplace=True)

#Amputaciones
#Conservamos aquellas personas con 60 años o más que han sufrido o no alguna amputación y puedan mantenerse de pie
df_antropometria = df_antropometria.loc[(df_antropometria['an11']!=2) & (df_antropometria['an11']!=3)] #amputaciones
df_antropometria.drop(['an11'], axis=1, inplace=True)

#Altura para personas de 20 a 59 años
#Se conservan aquellas mediciones que reportan no tener problema (an05=1) y se reemplazan con NaN aquellas observaciones con el código 222.22, pues representan mediciones no realizadas
df_antropometria[['altura1', 'altura2']] = df_antropometria[['altura1', 'altura2']].replace(222.22, np.nan)
df_antropometria = df_antropometria.loc[(df_antropometria['an05']!=2) & (df_antropometria['an05']!=3)]
df_antropometria.drop(['an05'], axis=1, inplace=True)

#Altura para personas con 60 años o más
#Se conservan aquellas mediciones que reportan no tener problema (an16=1) y se reemplazan con NaN aquellas observaciones con el código 222.22, pues representan mediciones no realizadas
df_antropometria[['an15_1','an15_2']] = df_antropometria[['an15_1','an15_2']].replace(222.22, np.nan)
#Si la columna de altura1 o altura2 están vacías (personas de 20 a 59 años), se les asigna el valor disponible para personas de 60 años o más respectivamente
df_antropometria['altura1'] = df_antropometria['altura1'].fillna(df_antropometria['an15_1'])
df_antropometria['altura2'] = df_antropometria['altura2'].fillna(df_antropometria['an15_2'])
df_antropometria = df_antropometria.loc[(df_antropometria['an16']!=2) & (df_antropometria['an16']!=3)]
df_antropometria.drop(['an16'], axis=1, inplace=True)
#Al haber concentrado la primera y segunda medición del peso en altura1 y altura2, eliminamos las columnas referentes a la primera y segunda medición del peso para personas de 60 o más años
df_antropometria.drop(['an15_1','an15_2'], axis=1, inplace=True)

#Embarazadas
#Conservamos aquellas mujeres no embarazadas o que dicen no saber si están embarazadas
df_antropometria = df_antropometria.loc[(df_antropometria['an06'] == 4) | (df_antropometria['an06'] == 9) | (df_antropometria['an06'].isna())]
df_antropometria.drop(['an06'], axis=1, inplace=True)


#Aquellos valores nulos son descartados
df_antropometria=df_antropometria.dropna()

#Se restablece el índice
df_antropometria.reset_index(drop=True,inplace=True)

df_antropometria.info()

df_examen_original=pd.read_csv("https://raw.githubusercontent.com/dxnxlsxn/Proyectos/refs/heads/main/Determinaciones_bioqu%C3%ADmicas_cronicas_deficiencias_9feb23.csv",sep=";")
#Se identifican las variables de interés
columnas_a_conservar = [
    'FOLIO_INT', 'entidad','h0302','h0303','san01','san04','hb01','valor_HB1AC','valor_AC_URICO', 'valor_ALBU', 'valor_COL_HDL', 'valor_COL_LDL',
    'valor_COLEST', 'valor_CREAT', 'valor_GLU_SUERO', 'valor_INSULINA', 'valor_TRIG'
]

# Seleccionar solo las columnas deseadas
df_examen = df_examen_original[columnas_a_conservar].copy()
#Se les asigna un nombre nuevo
df_examen.rename(columns={'h0302':'sexo','h0303':'edad','san04':'horas_en_ayuno','valor_HB1AC':'hemoglobina_glucosilada'}, inplace=True)

#Debido a que la mayoría de las variables en primera instancia son reconocidas como texto, se remueven los guiones bajos y las comas son reemplazadas por un punto
df_examen['FOLIO_INT']=df_examen['FOLIO_INT'].replace({'_': ''}, regex=True)
df_examen= df_examen.replace({',': '.'}, regex=True)
#Se transforman los datos al tipo número
df_examen = df_examen.apply(pd.to_numeric, errors='coerce')

df_examen=df_examen.dropna()

df_examen = df_examen.loc[(df_examen['san01']!=3) & (df_examen['san01']!=4)& (df_examen['san01']!=2)]
df_examen = df_examen.loc[(df_examen['hb01']!=3) & (df_examen['hb01']!=4)& (df_examen['san01']!=2)]


df_examen.drop(['san01','hb01'], axis=1, inplace=True)

df_examen.reset_index(drop=True,inplace=True)

df_examen.info()

df_diagnostico_original = pd.read_csv("https://raw.githubusercontent.com/dxnxlsxn/Proyectos/refs/heads/main/ensadul2022.csv", sep=";")

# Se identifican las variables de interés
columnas_a_conservar = [
    'FOLIO_INT', 'a0401','a0301'
]

# Seleccionar solo las columnas deseadas
df_diagnostico = df_diagnostico_original[columnas_a_conservar].copy()

# Se les asigna un nombre nuevo
df_diagnostico.rename(columns={'a0401': 'hipertension_diagnosticada','a0301': 'diabetes_diagnosticada'}, inplace=True)

# Debido a que la mayoría de las variables en primera instancia son reconocidas como texto,
# se remueven los guiones bajos y las comas son reemplazadas por un punto
df_diagnostico['FOLIO_INT'] = df_diagnostico['FOLIO_INT'].replace({'_': ''}, regex=True)
# df_diagnostico = df_diagnostico.replace({',': '.'}, regex=True)

# Se transforman los datos al tipo número
df_diagnostico = df_diagnostico.apply(pd.to_numeric, errors='coerce')

df_diagnostico = df_diagnostico.dropna()

df_diagnostico.reset_index(drop=True, inplace=True)

df_diagnostico['hipertension_diagnosticada'] = (df_diagnostico['hipertension_diagnosticada'] == 1).astype(int)
df_diagnostico['diabetes_diagnosticada'] = (df_diagnostico['diabetes_diagnosticada'] == 1).astype(int)

df_diagnostico.info()

df_aux = pd.merge(
    left=df_examen,           # Primer DataFrame
    right=df_antropometria,          # Segundo DataFrame
    on='FOLIO_INT',     # Columna común para la unión
    how='inner'         # Tipo de unión: inner join
)
df_2022 = pd.merge(
    left=df_aux,           # Primer DataFrame
    right=df_diagnostico,          # Segundo DataFrame
    on='FOLIO_INT',     # Columna común para la unión
    how='inner'         # Tipo de unión: inner join
)

df_2022.info()

df_2022["hipertension_diagnosticada"].unique()

#1-Hombre, 2-Mujer
df_examen_original_2020=pd.read_csv("https://raw.githubusercontent.com/dxnxlsxn/Proyectos/refs/heads/main/toma_de_sangre_ensanut2020_diab_w.csv")
#Se identifican las variables de interés
columnas_a_conservar = [
    'FOLIO_INT', 'ENTIDAD','H0302','H0303','san01','san04','HB1AC.Valor','valor.AC_URICO', 'valor.ALBUM', 'valor.COL_HDL', 'valor.COL_LDL',
    'valor.COLEST', 'valor.CREAT', 'valor.GLU_SUERO', 'valor.INSULINA', 'valor.TRIG'
]


# Seleccionar solo las columnas deseadas
df_examen_2020 = df_examen_original_2020[columnas_a_conservar].copy()
#Se les asigna un nombre nuevo
df_examen_2020.rename(columns={'ENTIDAD':'entidad','H0302':'sexo','H0303':'edad','san04':'horas_en_ayuno','HB1AC.Valor':'hemoglobina_glucosilada','valor.AC_URICO':'valor_AC_URICO',
                               'valor.ALBUM':'valor_ALBU','valor.COL_HDL':'valor_COL_HDL','valor.COL_LDL':'valor_COL_LDL','valor.COLEST':'valor_COLEST',
                               'valor.CREAT':'valor_CREAT','valor.GLU_SUERO':'valor_GLU_SUERO','valor.INSULINA':'valor_INSULINA', 'valor.TRIG':'valor_TRIG'}, inplace=True)

#Debido a que la mayoría de las variables en primera instancia son reconocidas como texto, se remueven los guiones bajos y las comas son reemplazadas por un punto
df_examen_2020['FOLIO_INT']=df_examen_2020['FOLIO_INT'].replace({'_': ''}, regex=True)
#df_examen_2020= df_examen_2020.replace({',': '.'}, regex=True)
#Se transforman los datos al tipo número
df_examen_2020 = df_examen_2020.apply(pd.to_numeric, errors='coerce')

df_examen_2020=df_examen_2020.dropna()

df_examen_2020 = df_examen_2020.loc[(df_examen_2020['san01']!=3) & (df_examen_2020['san01']!=4) & (df_examen_2020['san01']!=2)& (df_examen_2020['san01']!=5)& (df_examen_2020['san01']!=6)]


df_examen_2020.drop(['san01'], axis=1, inplace=True)

df_examen_2020.reset_index(drop=True,inplace=True)

df_examen_2020.info()

df_antropometria_original_2020 = pd.read_csv("https://raw.githubusercontent.com/dxnxlsxn/Proyectos/refs/heads/main/antropometria_ensanut2020_w.csv")

# Se identifican las variables de interés
columnas_a_conservar = [
    'FOLIO_INT', 'an08_01s','an08_02s','an08_03s','an08_01d','an08_02d','an08_03d','an11','an01_1','an01_2','an03',
    'an04_01','an04_02','an05','an06'
]

# Seleccionar solo las columnas deseadas
df_antropometria_2020 = df_antropometria_original_2020[columnas_a_conservar].copy()

# Se les asigna un nombre nuevo
df_antropometria_2020.rename(columns={'an08_01s':'tension_sistolica1', 'an08_02s':'tension_sistolica2','an08_03s':'tension_sistolica3',
                                      'an08_01d':'tension_diastolica1','an08_02d':'tension_diastolica2','an08_03d':'tension_diastolica3',
                                      'an01_1':'peso1','an01_2':'peso2','an04_01':'altura1','an04_02':'altura2',
                                      'an08_1':'cintura1','an08_2':'cintura2'}, inplace=True)

# Se remueven los guiones bajos y las comas se reemplazan por un punto
df_antropometria_2020['FOLIO_INT'] = df_antropometria_2020['FOLIO_INT'].replace({'_': ''}, regex=True)

# Se transforman los datos al tipo numérico
df_antropometria_2020 = df_antropometria_2020.apply(pd.to_numeric, errors='coerce')

# Tensión arterial
df_antropometria_2020 = df_antropometria_2020.loc[(df_antropometria_2020['an11'] == 1)]
df_antropometria_2020.drop(['an11'], axis=1, inplace=True)

# Peso corporal para personas de 20 años o más
df_antropometria_2020[['peso1', 'peso2']] = df_antropometria_2020[['peso1', 'peso2']].replace(222.00, np.nan)
df_antropometria_2020[['peso1', 'peso2']] = df_antropometria_2020[['peso1', 'peso2']].replace(22.00, np.nan)
df_antropometria_2020 = df_antropometria_2020.loc[(df_antropometria_2020['an03'] != 2) & (df_antropometria_2020['an03'] != 3) &
                                                  (df_antropometria_2020['an03'] != 4) & (df_antropometria_2020['an03'] != 5) &
                                                  (df_antropometria_2020['an03'] != 6)]
df_antropometria_2020.drop(['an03'], axis=1, inplace=True)

# Altura para personas de 20 años o más
df_antropometria_2020[['altura1', 'altura2']] = df_antropometria_2020[['altura1', 'altura2']].replace(222.00, np.nan)
df_antropometria_2020[['altura1', 'altura2']] = df_antropometria_2020[['altura1', 'altura2']].replace(2.00, np.nan)
df_antropometria_2020 = df_antropometria_2020.loc[(df_antropometria_2020['an05'] != 2) & (df_antropometria_2020['an05'] != 3) &
                                                  (df_antropometria_2020['an05'] != 4) & (df_antropometria_2020['an05'] != 5) &
                                                  (df_antropometria_2020['an05'] != 6)]
df_antropometria_2020.drop(['an05'], axis=1, inplace=True)

# Embarazadas
df_antropometria_2020 = df_antropometria_2020.loc[(df_antropometria_2020['an06'] == 4) | (df_antropometria_2020['an06'] == 9) |
                                                  (df_antropometria_2020['an06'].isna())]
df_antropometria_2020.drop(['an06'], axis=1, inplace=True)

# Se eliminan valores nulos
df_antropometria_2020 = df_antropometria_2020.dropna()

# Se restablece el índice
df_antropometria_2020.reset_index(drop=True, inplace=True)

df_antropometria_2020.head(20)

df_diagnostico2020_original = pd.read_csv("https://raw.githubusercontent.com/dxnxlsxn/Proyectos/refs/heads/main/integrantes_ensanut2020_w.csv", sep=";")

# Se identifican las variables de interés
columnas_a_conservar = [
    'FOLIO_INT', 'H0902A','H0902B','H0902C','H0902D','H0902E','H0902F','H0902G','H0902H'
]

# Seleccionar solo las columnas deseadas
df_diagnostico2020 = df_diagnostico2020_original[columnas_a_conservar].copy()

# Debido a que la mayoría de las variables en primera instancia son reconocidas como texto,
# se remueven los guiones bajos y las comas son reemplazadas por un punto

df_diagnostico2020['FOLIO_INT'] = df_diagnostico2020['FOLIO_INT'].replace({'_': ''}, regex=True)
df_diagnostico2020['FOLIO_INT'] = df_diagnostico2020['FOLIO_INT'].astype(str).str.slice(start=4)

# Se transforman los datos al tipo número
df_diagnostico2020 = df_diagnostico2020.apply(pd.to_numeric, errors='coerce')

# Crear la nueva columna de diagnóstico de hipertensión con 1 si hay al menos un 3, de lo contrario 0
df_diagnostico2020['hipertension_diagnosticada'] = df_diagnostico2020[['H0902A', 'H0902B', 'H0902C', 'H0902D', 'H0902E', 'H0902F', 'H0902G', 'H0902H']].apply(lambda row: 1 if (row == 3).any() else 0, axis=1)
# Crear la nueva columna de diagnóstico de hipertensión con 1 si hay al menos un 1, de lo contrario 0
df_diagnostico2020['diabetes_diagnosticada'] = df_diagnostico2020[['H0902A', 'H0902B', 'H0902C', 'H0902D', 'H0902E', 'H0902F', 'H0902G', 'H0902H']].apply(lambda row: 1 if (row == 1).any() else 0, axis=1)

df_diagnostico2020.drop(['H0902A', 'H0902B', 'H0902C', 'H0902D', 'H0902E', 'H0902F', 'H0902G', 'H0902H'], axis=1, inplace=True)
#df_diagnostico2020 = df_diagnostico2020.dropna()

df_diagnostico2020.reset_index(drop=True, inplace=True)

#df_diagnostico2020['hipertension_diagnosticada'] = (df_diagnostico2020['hipertension_diagnosticada'] == 3).astype(int)

df_diagnostico2020.head()

df_aux = pd.merge(
    left=df_examen_2020,           # Primer DataFrame
    right=df_antropometria_2020,          # Segundo DataFrame
    on='FOLIO_INT',     # Columna común para la unión
    how='inner'         # Tipo de unión: inner join
)
df_2020 = pd.merge(
    left=df_aux,           # Primer DataFrame
    right=df_diagnostico2020,          # Segundo DataFrame
    on='FOLIO_INT',     # Columna común para la unión
    how='inner'         # Tipo de unión: inner join
)
df_2020.info()

df_2022.info()

df = pd.concat([df_2022, df_2020], ignore_index=True)
df=df[df["horas_en_ayuno"]>=8]
df.drop(["horas_en_ayuno"],axis=1,inplace=True)
df.info()

df.describe()

def Mahalanobis_Robusta(df):
  df_filtrado=df.drop("FOLIO_INT",axis=1).copy()
  df_array=df_filtrado.to_numpy()
  #matriz de covarianza con el determinante más pequeño
  mcd=MinCovDet(random_state=8).fit(df_array)
  #estimación del centroide sin outliers
  mcd.location_
  #estimador de la matriz de covarianza sin outliers por mcd
  covarianza_mcd=mcd.covariance_
  inv_covarianza_mcd=np.linalg.inv(covarianza_mcd)
  distancias=[]
  for i in df_array:
    dist=mahalanobis(i,mcd.location_,inv_covarianza_mcd)
    distancias.append(dist)
  #p-valor
  gradoslibertad = df_filtrado.shape[1]
  p=1-chi2.cdf(distancias,gradoslibertad)
  outliers=p<0.05
  indices_outliers=np.where(outliers)[0]
  individuos=df.iloc[indices_outliers]

  return individuos, indices_outliers

Mahalanobis_Robusta(df[["FOLIO_INT",'tension_sistolica1','tension_sistolica2','tension_sistolica3']])
a, b = Mahalanobis_Robusta(df[["FOLIO_INT",'tension_sistolica1','tension_sistolica2','tension_sistolica3']])

df.drop(df.index[b],inplace=True)  # Usamos df.index para garantizar que los índices son correctos
df.reset_index(drop=True, inplace=True)
a

Mahalanobis_Robusta(df[["FOLIO_INT",'tension_diastolica1','tension_diastolica2','tension_diastolica3']])
a, b = Mahalanobis_Robusta(df[["FOLIO_INT",'tension_diastolica1','tension_diastolica2','tension_diastolica3']])

df.drop(df.index[b],inplace=True)  # Usamos df.index para garantizar que los índices son correctos
df.reset_index(drop=True, inplace=True)
a

df.info()

"""# **Transformaciones**"""

#Estatura
df['estatura']=(df['altura1']+df['altura2'])/2
#Peso
df['peso']=(df['peso1']+df['peso2'])/2
df.drop(['altura1','altura2','peso1','peso2'],axis=1,inplace=True)

#imc
df['imc']=df['peso']/(df['estatura']/100)**2

#Promedio usando las últimas dos mediciones de tensión arterial sistólica (PAS)
df['tension_sistolica_promedio2']=(df['tension_sistolica2']+df['tension_sistolica3'])/2
#PPromedio usando las últimas dos mediciones de tensión  (PAD)
df['tension_diastolica_promedio2']=(df['tension_diastolica2']+df['tension_diastolica3'])/2

# Criterio del promedio de las últimas dos mediciones
df['hipertension'] = ((df['tension_sistolica_promedio2'] >= 140) | (df['tension_diastolica_promedio2'] >= 90) | (df['hipertension_diagnosticada'] == 1)).astype(int)

#Posible diabetes
df['diabetes'] = ((df['hemoglobina_glucosilada'] >= 6.5) | (df['diabetes_diagnosticada'] == 1)).astype(int)

#Valor colesterol no HDL
df['valor_COL_NoHDL'] = df['valor_COLEST'] - df['valor_COL_HDL']

df['hiperglicemia'] = ((df['valor_GLU_SUERO'] >= 100)).astype(int)

#Dislipidemia Probable DLP se considera como caso probable de DLP a la persona que en una toma
#ocasional para su detección, obtenga un nivel de CT => 200 mg/dL o TG =>150 mg/dL o cHDL < 40
#mg/dL en el hombre y < 50 mg/dL en la mujer o cNoHDL =>160 mg/dL.

df['DLP_probable'] = ((df['valor_COLEST'] >= 200) | (df['valor_TRIG'] >= 150) |
                      ((df['sexo'] == 1) & (df['valor_COL_HDL'] < 40)) | ((df['sexo'] == 2) & (df['valor_COL_HDL'] < 50)) | (df['valor_COL_NoHDL'] >= 160)).astype(int)

df['hiperlipidemia_mixta'] = ((df['valor_COLEST'] > 200) & (df['valor_TRIG'] > 150)).astype(int)

df['hipertrigliceridemia'] = (df['valor_TRIG'] >= 150).astype(int)

df['hipercolesterolemia_pura'] = ((df['valor_COLEST'] > 200) & (df['valor_TRIG'] < 150) &
                                   (((df['sexo'] == 1) & (df['valor_COL_HDL'] > 40)) |
                                    ((df['sexo'] == 2) & (df['valor_COL_HDL'] > 50)))).astype(int)

df['hipoalfalipoproteinemia'] = (((df['sexo'] == 1) & (df['valor_COL_HDL'] < 40)) |
                                  ((df['sexo'] == 2) & (df['valor_COL_HDL'] < 50))).astype(int)

df['acido_urico_elevado'] = (
    ((df['sexo'] == 2) & (df['valor_AC_URICO'] >= 6)) |
    ((df['sexo'] == 1) & (df['valor_AC_URICO'] >= 7))
).astype(int)


def clasificar_imc(imc):
    if imc < 18.5:
        return 'bajo peso'
    elif 18.5 <= imc < 25.0:
        return 'peso normal'
    elif 25.0 <= imc < 30.0:
        return 'sobrepeso'
    else:
        return 'obesidad'

# Aplicar la función a la columna 'imc'
df['categoria_imc'] = df['imc'].apply(clasificar_imc)

#Eliminar variables innecesarias
df.drop(['diabetes_diagnosticada','tension_sistolica1','tension_sistolica2','tension_sistolica3','tension_diastolica1','tension_diastolica2','tension_diastolica3',
         'tension_sistolica_promedio2','tension_diastolica_promedio2','hipertension_diagnosticada'],axis=1,inplace=True)

df.info()

df

estados_mexico = {
    1: "Aguascalientes",
    2: "Baja California",
    3: "Baja California Sur",
    4: "Campeche",
    5: "Coahuila de Zaragoza",
    6: "Colima",
    7: "Chiapas",
    8: "Chihuahua",
    9: "Ciudad de México",
    10: "Durango",
    11: "Guanajuato",
    12: "Guerrero",
    13: "Hidalgo",
    14: "Jalisco",
    15: "Estado de México",
    16: "Michoacán de Ocampo",
    17: "Morelos",
    18: "Nayarit",
    19: "Nuevo León",
    20: "Oaxaca",
    21: "Puebla",
    22: "Querétaro",
    23: "Quintana Roo",
    24: "San Luis Potosí",
    25: "Sinaloa",
    26: "Sonora",
    27: "Tabasco",
    28: "Tamaulipas",
    29: "Tlaxcala",
    30: "Veracruz de Ignacio de la Llave",
    31: "Yucatán",
    32: "Zacatecas"
}
df["entidad"] = df["entidad"].map(estados_mexico)
sns.countplot(data=df, x="entidad", palette="viridis")  # Cambia la paleta
plt.title("Distribución por Estado")
plt.xlabel("Estado")
plt.ylabel("Frecuencia")
plt.xticks(rotation=90)
plt.show()

df['hipertension'].sum()

df_hombres = df[df["sexo"] == 1].copy()
df_mujeres = df[df["sexo"] == 2].copy()

#Número de la muestra
df['FOLIO_INT'].count()
df_hombres['FOLIO_INT'].count()
df_mujeres['FOLIO_INT'].count()

#Gráfica de pastel del sexo
df['sexo_categoria'] = df['sexo'].map({1: 'Hombres', 2: 'Mujeres'})
conteo_sexo = df['sexo_categoria'].value_counts()
etiquetas = conteo_sexo.index.tolist()
plt.figure(figsize=(6, 6))
plt.pie(conteo_sexo.values, labels=etiquetas, autopct='%1.1f%%', colors=['skyblue', 'lightcoral'], startangle=90)
plt.title('Proporción de Hombres y Mujeres')
plt.show()

#Promedio de la edad
df['edad'].mean()
df_hombres['edad'].mean()
df_mujeres['edad'].mean()


#Gráfica de pastel de hipertensión
conteo_sexo = df['hipertension'].value_counts()
etiquetas = ['No padece hipertensión', 'Padece hipertensión']
plt.figure(figsize=(6, 6))
plt.pie(conteo_sexo.values, labels=etiquetas, autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'], startangle=90)
plt.title('Proporción de Hipertensión Arterial')
plt.show()

# 1. Número de la muestra
print(f"Número total de la muestra: {df['FOLIO_INT'].count()}")
print(f"Número de hombres: {df_hombres['FOLIO_INT'].count()}")
print(f"Número de mujeres: {df_mujeres['FOLIO_INT'].count()}")

# 2. Gráfica de pastel del sexo
conteo_sexo = df['sexo_categoria'].value_counts()
etiquetas = conteo_sexo.index.tolist()
df.drop('sexo_categoria', axis=1, inplace=True)
plt.figure(figsize=(6, 6))
plt.pie(conteo_sexo.values, labels=etiquetas, autopct='%1.1f%%', colors=['skyblue', 'lightcoral'], startangle=90)
plt.title('Proporción de Hombres y Mujeres')
plt.show()

# 3. Promedio de la edad
print(f"Promedio de edad total: {df['edad'].mean():.2f} años")
print(f"Promedio de edad en hombres: {df_hombres['edad'].mean():.2f} años")
print(f"Promedio de edad en mujeres: {df_mujeres['edad'].mean():.2f} años")

# 4. Gráfica de pastel de hipertensión
conteo_hipertension = df['hipertension'].value_counts()
etiquetas_hipertension = ['No padece hipertensión', 'Padece hipertensión']
plt.figure(figsize=(6, 6))
plt.pie(conteo_hipertension.values, labels=etiquetas_hipertension, autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'], startangle=90)
plt.title('Proporción de Hipertensión Arterial')
plt.show()

# 5. Gráfica del % de hipertensos por sexo
porcentaje_hombres = (df_hombres['hipertension'].sum() / df_hombres['FOLIO_INT'].count()) * 100
porcentaje_mujeres = (df_mujeres['hipertension'].sum() / df_mujeres['FOLIO_INT'].count()) * 100
print(f"Porcentaje de hombres hipertensos: {porcentaje_hombres:.2f}%")
print(f"Porcentaje de mujeres hipertensas: {porcentaje_mujeres:.2f}%")

#gráfica de barras
plt.figure(figsize=(8, 5))
sns.barplot(
    x=['Hombres', 'Mujeres'],
    y=[porcentaje_hombres, porcentaje_mujeres],
    palette="viridis"
)
# Añadir los valores encima de las barras
for i, porcentaje in enumerate([porcentaje_hombres, porcentaje_mujeres]):
    plt.text(i, porcentaje + 0.5, f"{porcentaje:.2f}%", ha='center')

plt.title("Porcentaje de hipertensos por sexo")
plt.xlabel("Sexo")
plt.ylabel("Porcentaje (%)")
plt.show()

# 1. Filtrar hipertensos
hipertensos = df[df['hipertension'] == 1]

# 2. Calcular porcentajes de enfermedades crónicas (con nombres sin _)
enfermedades_cronicas = [
    'diabetes', 'hiperglicemia', 'DLP_probable',
    'hiperlipidemia_mixta', 'hipercolesterolemia_pura', 'hipoalfalipoproteinemia','hipertrigliceridemia','acido_urico_elevado'
]

porcentajes = {}
for enfermedad in enfermedades_cronicas:
    porcentaje = (hipertensos[enfermedad].mean()) * 100
    porcentajes[enfermedad.replace('_', ' ')] = porcentaje  # Eliminar _

# 3. Calcular porcentajes de IMC (nombres sin _)
porcentajes_imc = hipertensos['categoria_imc'].value_counts(normalize=True) * 100
porcentajes_imc_df = porcentajes_imc.reset_index()
porcentajes_imc_df.columns = ['Enfermedad', 'Porcentaje']
porcentajes_imc_df['Enfermedad'] = porcentajes_imc_df['Enfermedad'].str.replace('_', ' ')  # Eliminar _

# 4. Combinar y ordenar
porcentajes_df = pd.DataFrame(list(porcentajes.items()), columns=['Enfermedad', 'Porcentaje'])
porcentajes_df = pd.concat([porcentajes_df, porcentajes_imc_df])
porcentajes_df = porcentajes_df.sort_values('Porcentaje', ascending=False)  # Ordenar

# 5. Graficar con porcentajes
plt.figure(figsize=(12, 6))
ax = sns.barplot(x='Enfermedad', y='Porcentaje', data=porcentajes_df, palette='viridis')

# Añadir porcentajes encima
for p in ax.patches:
    ax.text(p.get_x() + p.get_width()/2.,
            p.get_height() + 0.5,
            f'{p.get_height():.2f}%',
            ha='center')

plt.title('Porcentaje de Hipertensos con Enfermedades Crónicas y por Categoría de IMC')
plt.xlabel('Enfermedad Crónica / Categoría de IMC')
plt.ylabel('Porcentaje (%)')
plt.xticks(rotation=45)
plt.show()

# 1. Filtrar NO hipertensos
no_hipertensos = df[df['hipertension'] == 0]

# 2. Calcular porcentajes de enfermedades crónicas (con nombres sin _)
enfermedades_cronicas = [
    'diabetes', 'hiperglicemia', 'DLP_probable',
    'hiperlipidemia_mixta', 'hipercolesterolemia_pura', 'hipoalfalipoproteinemia',
    'hipertrigliceridemia', 'acido_urico_elevado'
]

porcentajes_no_hipertensos = {}
for enfermedad in enfermedades_cronicas:
    porcentaje = (no_hipertensos[enfermedad].mean()) * 100
    porcentajes_no_hipertensos[enfermedad.replace('_', ' ')] = porcentaje

# 3. Calcular porcentajes de IMC (nombres sin _)
porcentajes_imc_no_hipertensos = no_hipertensos['categoria_imc'].value_counts(normalize=True) * 100
porcentajes_imc_no_hipertensos_df = porcentajes_imc_no_hipertensos.reset_index()
porcentajes_imc_no_hipertensos_df.columns = ['Enfermedad', 'Porcentaje']
porcentajes_imc_no_hipertensos_df['Enfermedad'] = porcentajes_imc_no_hipertensos_df['Enfermedad'].str.replace('_', ' ')

# 4. Combinar y ordenar
porcentajes_df_no_hipertensos = pd.DataFrame(
    list(porcentajes_no_hipertensos.items()), columns=['Enfermedad', 'Porcentaje']
)
porcentajes_df_no_hipertensos = pd.concat([porcentajes_df_no_hipertensos, porcentajes_imc_no_hipertensos_df])
porcentajes_df_no_hipertensos = porcentajes_df_no_hipertensos.sort_values('Porcentaje', ascending=False)

# 5. Graficar
plt.figure(figsize=(12, 6))
ax = sns.barplot(x='Enfermedad', y='Porcentaje', data=porcentajes_df_no_hipertensos, palette='crest')

# Añadir etiquetas de porcentaje
for p in ax.patches:
    ax.text(p.get_x() + p.get_width()/2.,
            p.get_height() + 0.5,
            f'{p.get_height():.2f}%',
            ha='center')

plt.title('Porcentaje de No Hipertensos con Enfermedades Crónicas y por Categoría de IMC')
plt.xlabel('Enfermedad Crónica / Categoría de IMC')
plt.ylabel('Porcentaje (%)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

enfermedades_cronicas = [
    'diabetes', 'hiperglicemia', 'DLP_probable',
    'hiperlipidemia_mixta', 'hipercolesterolemia_pura',
    'hipoalfalipoproteinemia', 'hipertrigliceridemia', 'acido_urico_elevado'
]

# Función para obtener porcentajes
def obtener_porcentajes(df_grupo, grupo_label):
    porcentajes = {}
    # Comorbilidades
    for enfermedad in enfermedades_cronicas:
        porcentajes[enfermedad.replace('_', ' ')] = df_grupo[enfermedad].mean() * 100
    # Categorías de IMC
    imc_porcentajes = df_grupo['categoria_imc'].value_counts(normalize=True) * 100
    for cat, pct in imc_porcentajes.items():
        porcentajes[cat] = pct
    # Construir DataFrame
    return pd.DataFrame({
        'Condición': list(porcentajes.keys()),
        'Porcentaje': list(porcentajes.values()),
        'Grupo': grupo_label
    })

# Filtrar hipertensos y no hipertensos
df_hip = df[df['hipertension'] == 1]
df_no_hip = df[df['hipertension'] == 0]

# Crear DataFrames de porcentajes
df_por_hip = obtener_porcentajes(df_hip, 'Hipertensos')
df_por_no_hip = obtener_porcentajes(df_no_hip, 'No Hipertensos')

# Concatenar para comparación
df_comparacion = pd.concat([df_por_hip, df_por_no_hip], ignore_index=True)

# Graficar comparación
plt.figure(figsize=(14, 7))
sns.barplot(
    data=df_comparacion,
    x='Porcentaje', y='Condición', hue='Grupo',
    palette={'Hipertensos': 'red', 'No Hipertensos': 'lightgreen'}
)
plt.title('Comparación de Prevalencia de Comorbilidades e IMC\nHipertensos vs No Hipertensos')
plt.xlabel('Porcentaje (%)')
plt.ylabel('Comorbilidad / Categoría IMC')
plt.legend(title='Grupo')
plt.tight_layout()
plt.show()



# Definir los grupos etarios
bins = [20, 25, 45, 60, 100]
labels = ['Juventud (20-24 años)', 'Adultos jóvenes (25-44 años)', 'Adultos maduros (45-59 años)', 'Adultos mayores (60+ años)']

# Crear una nueva columna en el DataFrame para los grupos etarios
hipertensos['grupo_etario'] = pd.cut(hipertensos['edad'], bins=bins, labels=labels, right=False)

# Calcular el porcentaje de hipertensos por grupo etario
porcentaje_hipertensos_etario = hipertensos['grupo_etario'].value_counts(normalize=True) * 100
porcentaje_hipertensos_etario = porcentaje_hipertensos_etario.sort_index()  # Ordenar por índice

# Gráfica de barras para el porcentaje de hipertensos por grupo etario
plt.figure(figsize=(10, 6))
sns.barplot(x=porcentaje_hipertensos_etario.index, y=porcentaje_hipertensos_etario.values, palette='coolwarm')
plt.title('Porcentaje de Hipertensos por Grupo Etario')
plt.xlabel('Grupo Etario')
plt.ylabel('Porcentaje de Hipertensos (%)')
plt.xticks(rotation=45)
plt.show()

df.info()

import pandas as pd

# Suponiendo que ya tienes cargado tu DataFrame original: df

# Tabla de características generales: medias y desviaciones estándar
summary_stats = df[['edad', 'imc']].agg(['mean', 'std']).T
summary_stats = summary_stats.rename(columns={'mean': 'Media', 'std': 'Desv. Estándar'})
print("\n--- Medias y Desviaciones Estándar (Edad e IMC) ---")
print(summary_stats)

# Tabla de frecuencias para variables categóricas
# Sexo
freq_sexo = df['sexo'].map({1: 'Hombre', 2: 'Mujer'}).value_counts().to_frame('n')
freq_sexo['%'] = (freq_sexo['n'] / df.shape[0]) * 100
print("\n--- Frecuencia: Sexo ---")
print(freq_sexo)

# Categoría IMC
freq_imc_cat = df['categoria_imc'].value_counts().to_frame('n')
freq_imc_cat['%'] = (freq_imc_cat['n'] / df.shape[0]) * 100
print("\n--- Frecuencia: Categoría IMC ---")
print(freq_imc_cat)

# Hipertensión
freq_hipertension = df['hipertension'].map({0: 'No', 1: 'Sí'}).value_counts().to_frame('n')
freq_hipertension['%'] = (freq_hipertension['n'] / df.shape[0]) * 100
print("\n--- Frecuencia: Hipertensión ---")
print(freq_hipertension)

# Diabetes
freq_diabetes = df['diabetes'].map({0: 'No', 1: 'Sí'}).value_counts().to_frame('n')
freq_diabetes['%'] = (freq_diabetes['n'] / df.shape[0]) * 100
print("\n--- Frecuencia: Diabetes ---")
print(freq_diabetes)

# Dislipidemia probable
freq_dlp = df['DLP_probable'].map({0: 'No', 1: 'Sí'}).value_counts().to_frame('n')
freq_dlp['%'] = (freq_dlp['n'] / df.shape[0]) * 100
print("\n--- Frecuencia: DLP Probable ---")
print(freq_dlp)


# Crear grupos etarios
bins = [19, 24, 44, 59, float('inf')]
labels = ['20-24', '25-44', '45-59', '60+']
df['grupo_etario'] = pd.cut(df['edad'], bins=bins, labels=labels)

# Tabla de frecuencia de grupo etario
freq_etario = df['grupo_etario'].value_counts(sort=False).to_frame('n')
freq_etario['%'] = (freq_etario['n'] / df.shape[0]) * 100

print("\n--- Frecuencia: Grupo Etario ---")
print(freq_etario)

#corr_matrix =df.drop(['FOLIO_INT','entidad','categoria_imc'],axis=1).corr(method='spearman')

# Crear el mapa de calor
#plt.figure(figsize=(9, 7))  # Tamaño de la figura
#sns.heatmap(corr_matrix, annot=False, cmap="coolwarm", vmin=-1, vmax=1)
#plt.title("Mapa de calor de la matriz de correlación")
#plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

def regresion_logistica(df, target, predictors):
    """
    Aplica una regresión logística sobre un DataFrame.

    Parámetros:
    - df: DataFrame que contiene los datos.
    - target: Nombre de la columna objetivo (variable dependiente).
    - predictors: Lista de nombres de las columnas predictoras (variables independientes).

    Retorna:
    - model: Modelo de regresión logística entrenado.
    - accuracy: Precisión del modelo en el conjunto de prueba.
    - confusion: Matriz de confusión.
    - report: Reporte de clasificación.
    """
    # Separar las variables predictoras y la variable objetivo
    X = df[predictors]  # Variables predictoras
    y = df[target]      # Variable objetivo

    # Dividir los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

    # Crear y entrenar el modelo de regresión logística
    model = LogisticRegression(max_iter=500)
    model.fit(X_train, y_train)

    # Predecir en el conjunto de prueba
    y_pred = model.predict(X_test)

    # Calcular métricas de evaluación
    accuracy = accuracy_score(y_test, y_pred)
    confusion = confusion_matrix(y_test, y_pred)
    report = classification_report(y_test, y_pred)

    # Retornar el modelo y las métricas
    return model, accuracy, confusion, report

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, precision_recall_curve, auc
import matplotlib.pyplot as plt

def regresion_logistica(df, target, predictors):
    """
    Aplica una regresión logística sobre un DataFrame.

    Parámetros:
    - df: DataFrame que contiene los datos.
    - target: Nombre de la columna objetivo (variable dependiente).
    - predictors: Lista de nombres de las columnas predictoras (variables independientes).

    Retorna:
    - model: Modelo de regresión logística entrenado.
    - accuracy: Precisión del modelo en el conjunto de prueba.
    - confusion: Matriz de confusión.
    - report: Reporte de clasificación.
    """
    # Separar las variables predictoras y la variable objetivo
    X = df[predictors]  # Variables predictoras
    y = df[target]      # Variable objetivo

    # Dividir los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

    # Crear y entrenar el modelo de regresión logística
    model = LogisticRegression(max_iter=500)
    model.fit(X_train, y_train)

    # Predecir en el conjunto de prueba
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probabilidades para la clase positiva

    # Calcular métricas de evaluación
    accuracy = accuracy_score(y_test, y_pred)
    confusion = confusion_matrix(y_test, y_pred)
    report = classification_report(y_test, y_pred)

    # Calcular la curva ROC (TPR vs FPR)
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    roc_auc = auc(fpr, tpr)

    # Graficar la curva ROC (TPR vs FPR)
    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc="lower right")
    plt.show()

    # Calcular la curva Precision-Recall
    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
    pr_auc = auc(recall, precision)

    # Graficar la curva Precision-Recall
    plt.figure()
    plt.plot(recall, precision, color='blue', lw=2, label=f'Precision-Recall curve (area = {pr_auc:.2f})')
    plt.xlabel('Recall (True Positive Rate)')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc="lower left")
    plt.show()

    # Retornar el modelo y las métricas
    return model, accuracy, confusion, report

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, confusion_matrix, classification_report,
    roc_curve, precision_recall_curve, auc, f1_score, precision_score, recall_score
)
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

def regresion_logistica(df, target, predictors):
    # Separar datos
    X = df[predictors]
    y = df[target]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)

    # Entrenar modelo
    model = LogisticRegression(max_iter=500)
    model.fit(X_train, y_train)

    # Coeficientes y odds ratios
    coeficientes = pd.Series(model.coef_[0], index=predictors)
    odds_ratios = np.exp(coeficientes)

    # Predicciones de probabilidad
    y_proba = model.predict_proba(X_test)[:, 1]

    # Buscar umbral óptimo (maximiza F1-score)
    thresholds = np.linspace(0, 1, 200)
    f1_scores = [f1_score(y_test, y_proba >= t) for t in thresholds]
    best_threshold = thresholds[np.argmax(f1_scores)]

    # Predicciones usando el mejor umbral
    y_pred_opt = (y_proba >= best_threshold).astype(int)

    # Métricas con el umbral óptimo
    accuracy = accuracy_score(y_test, y_pred_opt)
    precision = precision_score(y_test, y_pred_opt)
    recall = recall_score(y_test, y_pred_opt)
    f1 = f1_score(y_test, y_pred_opt)
    confusion = confusion_matrix(y_test, y_pred_opt)
    report = classification_report(y_test, y_pred_opt)

    # ROC Curve
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_auc = auc(fpr, tpr)
    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlabel('Tasa de falsos positivos')
    plt.ylabel('Tasa de verdaderos positivos')
    plt.title('Curva ROC')
    plt.legend(loc="lower right")
    plt.grid(True)
    plt.show()

    # Precision-Recall Curve
    precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_proba)
    pr_auc = auc(recall_vals, precision_vals)
    plt.figure()
    plt.plot(recall_vals, precision_vals, color='blue', lw=2, label=f'Precisión-Recall curve (AUC = {pr_auc:.2f})')
    plt.xlabel('Recall')
    plt.ylabel('Precisión')
    plt.title('Curva Precision-Recall')
    plt.legend(loc="lower left")
    plt.grid(True)
    plt.show()

    # Diccionario de resultados
    metricas = {
        "best threshold (F1 max)": best_threshold,
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1 score": f1,
        "roc_auc": roc_auc,
        "pr_auc": pr_auc,
        "confusion_matrix": confusion,
        "classification_report": report
    }

    return model, metricas, coeficientes, odds_ratios

df.info()

# Definir las variables predictoras y la variable objetivo
predictors = ["edad", "sexo", "diabetes", "hiperglicemia", "hiperlipidemia_mixta",
              "valor_AC_URICO", "imc", "hipercolesterolemia_pura"]
target = 'hipertension'

# Aplicar la función de regresión logística
model, metricas, coefs, oratios = regresion_logistica(df, target, predictors)

# Imprimir métricas clave
print("Umbral óptimo:", metricas["best threshold (F1 max)"])
print("F1-score:", metricas["f1 score"])
print("Precisión:", metricas["precision"])
print("Recall:", metricas["recall"])
print("Matriz de confusión:\n", metricas["confusion_matrix"])

# Mostrar coeficientes y odds ratios
print("\nCoeficientes del modelo:")
print(coefs)

print("\nOdds Ratios (exp(coef)):")
print(oratios)

